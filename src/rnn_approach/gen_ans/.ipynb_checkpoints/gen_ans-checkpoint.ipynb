{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "51m5I4oG2jsa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.legacy_seq2seq as seq2seq\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import load_data\n",
    "import nltk\n",
    "from IPython.display import HTML\n",
    "import utilities\n",
    "from time import gmtime, strftime\n",
    "import random\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hwvUr2573mO3"
   },
   "outputs": [],
   "source": [
    "ques_data = load_data.load_ip('../gen_data/Musical_Instruments/Musical_Instruments_question_file.txt')\n",
    "rev_data = load_data.load_ip('../gen_data/Musical_Instruments/Musical_Instruments_review_file.txt')\n",
    "ans_data = load_data.load_labels('../gen_data/Musical_Instruments/Musical_Instruments_answer_file.txt')\n",
    "\n",
    "zipped = list(zip(ques_data, rev_data, ans_data))\n",
    "random.shuffle(zipped)\n",
    "ques_data, rev_data, ans_data = zip(*zipped)\n",
    "\n",
    "data = {\"questions\": ques_data,\n",
    "        \"reviews\": rev_data,\n",
    "        \"answers\": ans_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1523874826899,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "dvYGT30U3q-L",
    "outputId": "a3226f1c-2e4c-4e1f-ffb3-97e7d9d02a82"
   },
   "outputs": [],
   "source": [
    "def get_unique_words(data):\n",
    "    unique_words = []\n",
    "\n",
    "    for index in range(len(data[\"questions\"])):\n",
    "        sample_data = data[\"questions\"][index] + data[\"reviews\"][index] + data[\"answers\"][index]\n",
    "        sample_data = list(set(sample_data))\n",
    "        unique_words.extend(sample_data)\n",
    "        unique_words = list(set(unique_words))\n",
    "\n",
    "    unique_words = [\"<PAD>\"] + [\"<UNK>\"] + unique_words\n",
    "\n",
    "    return unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1523874826899,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "dvYGT30U3q-L",
    "outputId": "a3226f1c-2e4c-4e1f-ffb3-97e7d9d02a82"
   },
   "outputs": [],
   "source": [
    "def build_vocabs(unique_words):\n",
    "    word2idx = {value:index for index, value in enumerate(unique_words)}\n",
    "    idx2word = {index:value for index, value in enumerate(unique_words)}\n",
    "    \n",
    "    return word2idx, idx2word, len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1523874826899,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "dvYGT30U3q-L",
    "outputId": "a3226f1c-2e4c-4e1f-ffb3-97e7d9d02a82"
   },
   "outputs": [],
   "source": [
    "# unique_words = get_unique_words(data)\n",
    "# with open(\"unique_words.p\", \"wb\") as pickle_d:\n",
    "#     pickle.dump(unique_words, pickle_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1523874826899,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "dvYGT30U3q-L",
    "outputId": "a3226f1c-2e4c-4e1f-ffb3-97e7d9d02a82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10277 3559 0 2108 1\n"
     ]
    }
   ],
   "source": [
    "unique_words = pickle.load(open('unique_words.p', 'rb'))\n",
    "word2idx, idx2word, vocab_size = build_vocabs(unique_words)\n",
    "print (vocab_size, word2idx[\"<START>\"], word2idx[\"<PAD>\"], word2idx[\"<EOS>\"], word2idx[\"<UNK>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1523874827277,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "poiHJgQi3s7B",
    "outputId": "c47ce5fe-1f86-4923-f4b6-9af1bfa51b88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n"
     ]
    }
   ],
   "source": [
    "train_samples = 55000\n",
    "train_X = [data[\"questions\"][:train_samples], data[\"reviews\"][:train_samples]]\n",
    "train_Y = data[\"answers\"][:train_samples]\n",
    "test_X = [data[\"questions\"][train_samples:], data[\"reviews\"][train_samples:]]\n",
    "test_Y = data[\"answers\"][train_samples:]\n",
    "print (len(train_X[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "24rPvy8L3vH_"
   },
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, lengths, batch_size):\n",
    "    max_len = max(lengths)\n",
    "    for i in range (batch_size):\n",
    "        diff = max_len - lengths[i]\n",
    "        sequences[i] += [word2idx[\"<PAD>\"]] * diff\n",
    "\n",
    "    return np.asarray(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "24rPvy8L3vH_"
   },
   "outputs": [],
   "source": [
    "def batch_data(X, Y, batch_size):\n",
    "    start = 0\n",
    "    while start + batch_size <= len(X[0]):\n",
    "        enc_batch_input = list()\n",
    "        con_enc_batch_input = list()\n",
    "        dec_batch_input = list()\n",
    "        dec_batch_target = list()\n",
    "        enc_inp_lens = list()\n",
    "        con_enc_inp_lens = list()\n",
    "        dec_inp_lens = list()\n",
    "        target_w = list()\n",
    "        for index in range(start, start + batch_size):\n",
    "            batch_index = index - start\n",
    "\n",
    "            enc_batch_input.append([])\n",
    "            for word_index, word in enumerate(X[0][index]):\n",
    "                enc_batch_input[-1].append(word2idx[word])\n",
    "            enc_inp_lens.append(len(enc_batch_input[-1]))\n",
    "            \n",
    "            con_enc_batch_input.append([])\n",
    "            for word_index, word in enumerate(X[1][index]):\n",
    "                con_enc_batch_input[-1].append(word2idx[word])\n",
    "            con_enc_inp_lens.append(len(con_enc_batch_input[-1]))\n",
    "\n",
    "            dec_batch_input.append([])\n",
    "            for word_index, word in enumerate(Y[index][:-1]):\n",
    "                dec_batch_input[-1].append(word2idx[word])\n",
    "            dec_inp_lens.append(len(dec_batch_input[-1]))\n",
    "\n",
    "            dec_batch_target.append([])\n",
    "            for word_index, word in enumerate(Y[index][1:]):\n",
    "                dec_batch_target[-1].append(word2idx[word])\n",
    "        \n",
    "        for batch_i in range(batch_size):\n",
    "            pad = [1] * dec_inp_lens[batch_i]\n",
    "            diff = max(dec_inp_lens) - dec_inp_lens[batch_i]\n",
    "            pad.extend([0] * diff)\n",
    "            target_w.append(pad)\n",
    "\n",
    "        enc_batch_input = pad_sequences(enc_batch_input, enc_inp_lens, batch_size)\n",
    "        con_enc_batch_input = pad_sequences(con_enc_batch_input, con_enc_inp_lens, batch_size)\n",
    "        dec_batch_input = pad_sequences(dec_batch_input, dec_inp_lens, batch_size)\n",
    "        dec_batch_target = pad_sequences(dec_batch_target, dec_inp_lens, batch_size)\n",
    "\n",
    "        enc_inp_lens = np.asarray(enc_inp_lens)\n",
    "        con_enc_inp_lens = np.asarray(con_enc_inp_lens)\n",
    "        dec_inp_lens = np.asarray(dec_inp_lens)\n",
    "        target_w = np.asarray(target_w)\n",
    "\n",
    "        yield enc_batch_input, con_enc_batch_input, dec_batch_input, dec_batch_target, enc_inp_lens, \\\n",
    "            con_enc_inp_lens, dec_inp_lens, target_w\n",
    "        \n",
    "        start += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v3gnRQ1l3xSU"
   },
   "outputs": [],
   "source": [
    "embedding_size = 300\n",
    "input_num_units = 96\n",
    "context_num_units = 32\n",
    "decoder_num_units = 256\n",
    "keep_prob = 0.75\n",
    "\n",
    "assert ((input_num_units+context_num_units) * 2 == decoder_num_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "s_lsEZeg3zdw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "\n",
    "encoder_inputs = tf.placeholder(tf.int32, [None, None], 'encoder_inputs')\n",
    "context_encoder_inputs = tf.placeholder(tf.int32, [None, None], 'context_encoder_inputs')\n",
    "decoder_inputs = tf.placeholder(tf.int32, [None, None], 'decoder_inputs')\n",
    "decoder_targets = tf.placeholder(tf.int32, [None, None], 'decoder_targets')\n",
    "encoder_lengths = tf.placeholder(tf.int32, [None], 'encoder_lengths')\n",
    "context_encoder_lengths = tf.placeholder(tf.int32, [None], 'context_encoder_lengths')\n",
    "decoder_lengths = tf.placeholder(tf.int32, [None], 'decoder_lengths')\n",
    "target_weights = tf.placeholder(tf.float32, [None, None], 'target_weights')\n",
    "learning_rate = tf.placeholder(tf.float32, [], 'learning_rate')\n",
    "batch_size = tf.placeholder(tf.int32, [], 'batch_size')\n",
    "\n",
    "# Embedding\n",
    "with tf.variable_scope(\"embeddings\"):\n",
    "    embedding_encoder = tf.get_variable(\n",
    "        \"embedding_encoder\", [vocab_size, embedding_size])\n",
    "\n",
    "    encoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_encoder, encoder_inputs)\n",
    "\n",
    "    context_encoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_encoder, context_encoder_inputs)\n",
    "\n",
    "    decoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_encoder, decoder_inputs)\n",
    "\n",
    "\n",
    "with tf.variable_scope('encoder_lstm'):\n",
    "    enc_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(\n",
    "        input_num_units, state_is_tuple=True, name=\"enc_fw\")\n",
    "    \n",
    "    enc_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(\n",
    "        input_num_units, state_is_tuple=True, name=\"enc_bw\")\n",
    "    \n",
    "    enc_fw_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        enc_fw_cell, input_keep_prob = keep_prob)\n",
    "    \n",
    "    enc_bw_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        enc_bw_cell, input_keep_prob = keep_prob)\n",
    "\n",
    "#     encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "#         encoder_cell, encoder_emb_inp,\n",
    "#         sequence_length=encoder_lengths, dtype=tf.float32)\n",
    "\n",
    "    enc_bi_outputs, encoder_state = tf.nn.bidirectional_dynamic_rnn(enc_fw_cell, enc_bw_cell, \\\n",
    "                                                                encoder_emb_inp, \\\n",
    "                                                                sequence_length=encoder_lengths, \\\n",
    "                                                                time_major=False, dtype=tf.float32)\n",
    "    encoder_outputs = tf.concat(enc_bi_outputs, -1)\n",
    "\n",
    "\n",
    "with tf.variable_scope('context_encoder_lstm'):\n",
    "    ce_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(\n",
    "        context_num_units, state_is_tuple=True, name=\"ce_fw\")\n",
    "\n",
    "    ce_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(\n",
    "        context_num_units, state_is_tuple=True, name=\"ce_bw\")\n",
    "    \n",
    "    ce_fw_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        ce_fw_cell, input_keep_prob = keep_prob)\n",
    "    \n",
    "    ce_bw_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        ce_bw_cell, input_keep_prob = keep_prob)\n",
    "\n",
    "#     context_encoder_outputs, context_encoder_state = tf.nn.dynamic_rnn(\n",
    "#         context_encoder_cell, context_encoder_emb_inp,\n",
    "#         sequence_length=context_encoder_lengths, dtype=tf.float32)\n",
    "\n",
    "    ce_bi_outputs, context_encoder_state = tf.nn.bidirectional_dynamic_rnn(ce_fw_cell, ce_bw_cell, \\\n",
    "                                                                context_encoder_emb_inp, \\\n",
    "                                                                sequence_length=context_encoder_lengths, \\\n",
    "                                                                time_major=False, dtype=tf.float32)\n",
    "    context_encoder_outputs = tf.concat(ce_bi_outputs, -1)\n",
    "\n",
    "with tf.variable_scope('decoder_lstm'):\n",
    "    total_c_state = tf.concat(axis=1,values=[encoder_state[0].c, encoder_state[1].c, \\\n",
    "                                             context_encoder_state[0].c, context_encoder_state[1].c])\n",
    "    total_h_state = tf.concat(axis=1,values=[encoder_state[0].h, encoder_state[1].h, \\\n",
    "                                             context_encoder_state[0].h, context_encoder_state[1].h])\n",
    "\n",
    "    total_state = tf.contrib.rnn.LSTMStateTuple(total_c_state, total_h_state)\n",
    "\n",
    "    decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(decoder_num_units, state_is_tuple=True, name=\"dec_lstm\")\n",
    "    \n",
    "    decoder_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        decoder_cell, input_keep_prob = keep_prob)\n",
    "\n",
    "    projection_layer = tf.layers.Dense(\n",
    "        vocab_size, use_bias=False)\n",
    "\n",
    "    # attention_states: [batch_size, max_time, num_units]\n",
    "\n",
    "    attention_states = context_encoder_outputs # tf.transpose\n",
    "\n",
    "    # Create an attention mechanism\n",
    "    attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "        decoder_num_units, attention_states,\n",
    "        memory_sequence_length=decoder_lengths)\n",
    "    \n",
    "    decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "        decoder_cell, attention_mechanism,\n",
    "        attention_layer_size=decoder_num_units)\n",
    "    \n",
    "    initial_state = decoder_cell.zero_state(dtype = tf.float32, batch_size=batch_size)\n",
    "    initial_state = initial_state.clone(cell_state=total_state)\n",
    "\n",
    "    # Helper\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "        decoder_emb_inp, decoder_lengths)\n",
    "\n",
    "    # Decoder\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        decoder_cell, helper, initial_state,\n",
    "        output_layer=projection_layer)\n",
    "\n",
    "    # Dynamic decoding\n",
    "    decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "\n",
    "    logits = decoder_outputs.rnn_output\n",
    "\n",
    "with tf.variable_scope('loss'):\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=decoder_targets, logits=logits)\n",
    "\n",
    "    train_loss = tf.reduce_sum(loss * target_weights)\n",
    "\n",
    "with tf.variable_scope('optimization'):\n",
    "    # Calculate and clip gradients\n",
    "    max_gradient_norm = 1\n",
    "    params = tf.trainable_variables()\n",
    "    gradients = tf.gradients(train_loss, params)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(\n",
    "        gradients, max_gradient_norm)\n",
    "\n",
    "    # Optimization\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    update_step = optimizer.apply_gradients(\n",
    "        zip(clipped_gradients, params))\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6hZrnpwN8Nef"
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VovevJKI8gfe"
   },
   "outputs": [],
   "source": [
    "num_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2937
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1280601,
     "status": "error",
     "timestamp": 1523876122094,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "vt-WB5y832id",
    "outputId": "dc171700-042a-41c8-c2a7-20c20fb14073"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [29:12,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 87.00921456473215 Accuracy: 0.0970873786407767 Epoch duration: 1752.9742629528046 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [29:08,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Loss: 74.86971261160714 Accuracy: 0.10762829403606103 Epoch duration: 1748.4938309192657 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [29:02,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Loss: 73.48782784598214 Accuracy: 0.10901525658807212 Epoch duration: 1742.0963327884674 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [29:02,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Loss: 50.211802455357144 Accuracy: 0.1319001386962552 Epoch duration: 1742.6694738864899 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [29:03,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Loss: 44.30073939732143 Accuracy: 0.1378640776699029 Epoch duration: 1743.3598012924194 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [29:04,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Loss: 42.50959821428572 Accuracy: 0.140499306518724 Epoch duration: 1744.85400724411 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [29:05,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 Loss: 43.1927001953125 Accuracy: 0.1407766990291262 Epoch duration: 1745.5899007320404 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [29:05,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 Loss: 28.077804129464287 Accuracy: 0.15963938973647712 Epoch duration: 1745.6755084991455 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [29:05,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Loss: 27.729481724330356 Accuracy: 0.15908460471567268 Epoch duration: 1746.0738470554352 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1571it [29:03,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 Loss: 25.946843610491072 Accuracy: 0.16033287101248267 Epoch duration: 1743.9524500370026 s\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "bs = 35\n",
    "for epoch_i in range(epochs):\n",
    "    if epoch_i < 3:\n",
    "        lr = 0.01\n",
    "    elif epoch_i >= 3 and epoch_i < 6:\n",
    "        lr = 0.005\n",
    "    elif epoch_i >= 7 and epoch_i < epochs:\n",
    "        lr = 0.001\n",
    "        \n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch_i, (enc_batch_inputs, con_enc_batch_inputs, dec_batch_inputs, dec_batch_targets, \\\n",
    "                  enc_inp_lens, con_enc_inp_lens, dec_inp_lens, target_w) \\\n",
    "    in enumerate(tqdm(batch_data(train_X, train_Y, bs))):\n",
    "        _, batch_loss, batch_logits = sess.run([update_step, train_loss, logits],\n",
    "            feed_dict = {encoder_inputs: enc_batch_inputs,\n",
    "             context_encoder_inputs: con_enc_batch_inputs,\n",
    "             decoder_inputs: dec_batch_inputs,\n",
    "             decoder_targets: dec_batch_targets,\n",
    "             encoder_lengths: enc_inp_lens,\n",
    "             context_encoder_lengths: con_enc_inp_lens,\n",
    "             decoder_lengths: dec_inp_lens,\n",
    "             target_weights: target_w,\n",
    "             learning_rate: lr,\n",
    "             batch_size: bs})\n",
    "    num_epochs += 1\n",
    "    accuracy = np.mean(batch_logits.argmax(axis=-1) == dec_batch_targets)\n",
    "    print('Epoch:', epoch_i+1, 'Loss:', batch_loss/bs, 'Accuracy:', accuracy, 'Epoch duration:', (time.time() - start_time), 's')\n",
    "    saver.save(sess, './checkpoints/epoch_'+str(num_epochs)+\"_\"+str(strftime(\"%Y-%m-%d_%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "CB1NnHpp37LC"
   },
   "outputs": [],
   "source": [
    "def num2sent(pred, mode, seq_len=None):\n",
    "    res = \"\"\n",
    "    if mode == \"q\":\n",
    "        pred = pred[:seq_len]        \n",
    "        for idx in pred:\n",
    "            res += idx2word[idx] + \" \"\n",
    "    elif mode == \"t\":\n",
    "        pred = pred[:seq_len]\n",
    "        for idx in pred:\n",
    "            res += idx2word[idx] + \" \"\n",
    "    elif mode == \"a\":\n",
    "        pred = pred[1:-1]\n",
    "        for idx in pred:\n",
    "            res += idx2word[idx] + \" \"\n",
    "    return res, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sample(test_sess, ques, ques_len, review, rev_len, bs=1):\n",
    "    dec_input = np.zeros((1, 1)) + word2idx['<START>']\n",
    "    dec_len = [1]\n",
    "    while dec_input[0, -1] != word2idx['<EOS>']:\n",
    "        batch_logits = test_sess.run(\"decoder_lstm/decoder/transpose:0\",\n",
    "                       feed_dict = {\"encoder_inputs:0\": [ques],\n",
    "                                    \"context_encoder_inputs:0\": [review],\n",
    "                                    \"decoder_inputs:0\": dec_input,\n",
    "                                    \"encoder_lengths:0\": [ques_len],\n",
    "                                    \"context_encoder_lengths:0\": [rev_len],\n",
    "                                    \"decoder_lengths:0\": dec_len,\n",
    "                                    \"batch_size:0\": bs})\n",
    "        prediction = batch_logits[:,-1].argmax(axis=-1)\n",
    "        dec_len[0] += 1\n",
    "\n",
    "        dec_input = np.hstack([dec_input, prediction[:,None]])\n",
    "\n",
    "    return dec_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eTlGmhnH38Ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/epoch_10_2018-04-23_09:25:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "\n",
      "1it [00:36, 36.64s/it]\u001b[A\n",
      "2it [00:59, 29.83s/it]\u001b[A/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n",
      "\n",
      "3it [01:12, 24.30s/it]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU score: 0.16741537486766345\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_batch_size = 35\n",
    "model = \"epoch_10_2018-04-23_09:25:56\"\n",
    "with tf.Session() as test_sess:\n",
    "    saver = tf.train.import_meta_graph('./checkpoints/'+model+'.meta')\n",
    "    saver.restore(test_sess, tf.train.latest_checkpoint('./checkpoints/'))\n",
    "    bleu_scores = []\n",
    "    for batch_i, (enc_batch_inputs, con_enc_batch_inputs, dec_batch_inputs, dec_batch_targets, \\\n",
    "        enc_inp_lens, con_enc_inp_lens, dec_inp_lens, target_w) \\\n",
    "        in enumerate(tqdm(batch_data([test_X[0][-105:], test_X[1][-105:]], test_Y[-105:], test_batch_size))):\n",
    "\n",
    "        for index, sample in enumerate(enc_batch_inputs):\n",
    "            pred = test_sample(test_sess, sample, enc_inp_lens[index], con_enc_batch_inputs[index], \\\n",
    "                               con_enc_inp_lens[index])\n",
    "\n",
    "            ip_str, ip_list = num2sent(sample, mode=\"q\", seq_len=enc_inp_lens[index])\n",
    "            target_str, target_list = num2sent(dec_batch_targets[index], mode=\"t\", seq_len=dec_inp_lens[index])\n",
    "            pred_str, pred_list = num2sent(pred, mode=\"a\")\n",
    "\n",
    "            bleu_scores.append(sentence_bleu([target_list], pred_list))\n",
    "\n",
    "    print(\"Average BLEU score:\", np.mean(bleu_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/epoch_10_2018-04-23_09:25:56\n",
      "\n",
      "Enter question ('!q' to quit):\tWill this work for bass guitars as well ?\n",
      "\n",
      "Enter review:\tI use a lot of these guys and if they work when you get them, they havn't failed yet. I like it and have used HOSA products in the past with confidence. Thick, a bit stiff and seems to be shielded. I use this cord in my church to run from my pedalboard to my amp (which is in a soundproof box).\n",
      "\n",
      "Answer:\t no \n",
      "\n",
      "Enter question ('!q' to quit):\tIs plug and play simple ?\n",
      "\n",
      "Enter review:\tRecord companies and file hosts are increasingly anachronistic due to tech like this JAM, and maybe soon enough we'll see artists keeping ALL of the profits from their art. Given the cost of an new iPhone or iPad, the cost of the JAM is rather trivial in comparison. It's simple to use, has no detectable latency, and delivers excellent sound quality. BUT: I haven't encountered anything so Plug & Play simple as the Apogee JAM 96k since Gefen introduced the iMic.\n",
      "\n",
      "Answer:\t yes \n",
      "\n",
      "Enter question ('!q' to quit):\t!q\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "model = \"epoch_10_2018-04-23_09:25:56\"\n",
    "with tf.Session() as demo_sess:\n",
    "    saver = tf.train.import_meta_graph('./checkpoints/'+model+'.meta')\n",
    "    saver.restore(demo_sess, tf.train.latest_checkpoint('./checkpoints/'))\n",
    "    writer = tf.summary.FileWriter('logs', demo_sess.graph)\n",
    "    ques = input(\"\\nEnter question ('!q' to quit):\\t\")\n",
    "    while ques != \"!q\":\n",
    "        ques = nltk.word_tokenize(ques)\n",
    "        ques = [token.lower() for token in ques]\n",
    "\n",
    "        for idx, word in enumerate(ques):\n",
    "            if word in word2idx:\n",
    "                ques[idx] = word2idx[word]\n",
    "            else:\n",
    "                ques[idx] = word2idx[\"<UNK>\"]\n",
    "\n",
    "        ques += [word2idx['<EOS>']]\n",
    "\n",
    "        review = input(\"\\nEnter review:\\t\")\n",
    "        \n",
    "        review = nltk.word_tokenize(review)\n",
    "        review = [token.lower() for token in review]\n",
    "\n",
    "        for idx, word in enumerate(review):\n",
    "            if word in word2idx:\n",
    "                review[idx] = word2idx[word]\n",
    "            else:\n",
    "                review[idx] = word2idx[\"<UNK>\"]\n",
    "\n",
    "        review += [word2idx['<EOS>']]\n",
    "        \n",
    "        predict = test_sample(demo_sess, ques, len(ques), review, len(review))\n",
    "        prediction, _ = num2sent(predict, mode=\"a\")\n",
    "\n",
    "        print (\"\\nAnswer:\\t\", prediction)\n",
    "\n",
    "        ques = input(\"\\nEnter question ('!q' to quit):\\t\")\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "context.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
